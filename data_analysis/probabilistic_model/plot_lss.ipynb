{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rofarate/PIC-STELLARATOR/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Weibull import *\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from lightgbmlss.distributions.Mixture import *\n",
    "from lightgbmlss.distributions.mixture_distribution_utils import MixtureDistributionClass\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "figure_size = (10,5)\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "plotnine.options.figure_size = figure_size\n",
    "\n",
    "conn = sqlite3.connect('../../data/nfp2/nfp2.db')  # Adjust the path to your database file\n",
    "\n",
    "# Step 2 & 3: Query the database and load the data into a pandas DataFrame\n",
    "query = \"SELECT * FROM stellarators\"  # Adjust your query as needed\n",
    "data_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "data_df_clean = data_df[data_df['convergence'] == 1]\n",
    "data_df_clean = data_df_clean.dropna(subset=['quasisymmetry'])\n",
    "\n",
    "\n",
    "X = data_df_clean[['rbc_1_0', 'rbc_m1_1', 'rbc_0_1', 'rbc_1_1','zbs_1_0', 'zbs_m1_1', 'zbs_0_1', 'zbs_1_1']] \n",
    "Y = np.log(data_df_clean['quasisymmetry'])\n",
    "\n",
    "features_no_outliers, test_features_no_outliers, target_no_outliers, test_target_no_outliers = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Dataset with max_bin parameter specified\n",
    "dtrain = lgb.Dataset(features_no_outliers, label=target_no_outliers.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbmlss.model import LightGBMLSS  # Ensure this import matches your actual usage\n",
    "\n",
    "lgblss = LightGBMLSS(\n",
    "    Mixture(\n",
    "        Gaussian(response_fn=\"softplus\", stabilization=\"L2\"), \n",
    "        M = 9,\n",
    "        tau=1.0,\n",
    "        hessian_mode=\"individual\",\n",
    "    )\n",
    ")\n",
    "\n",
    "opt_params = {\n",
    "    \"max_depth\": 48,\n",
    "    \"num_leaves\": 16,\n",
    "    \"min_data_in_leaf\": 393,\n",
    "    \"min_gain_to_split\": 1.1556203491903734,\n",
    "    \"min_sum_hessian_in_leaf\":  110.92934181055902,\n",
    "    \"subsample\": 0.8890534795296703,\n",
    "    \"subsample_freq\": 18,\n",
    "    \"feature_fraction\": 0.9785823899781169,\n",
    "    \"boosting_type\": \"dart\",\n",
    "    \"learning_rate\": 0.3305647024869448,\n",
    "    \"max_delta_step\": 0.5871308608990791,\n",
    "    \"feature_pre_filter\": False,\n",
    "    \"boosting\": \"dart\",  # Assuming this value remains the same\n",
    "    \"opt_rounds\": 300  # Assuming this value remains the same\n",
    "}\n",
    "\n",
    "n_rounds = opt_params[\"opt_rounds\"]\n",
    "del opt_params[\"opt_rounds\"]\n",
    "\n",
    "lgblss.train(opt_params, dtrain, num_boost_round=n_rounds)\n",
    "\n",
    "# Seed for reproducibility in torch operations\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Number of samples to draw from predicted distribution\n",
    "n_samples = len(test_target_no_outliers)  # Use the number of rows in X_test as the number of samples\n",
    "\n",
    "# Quantiles to calculate from predicted distribution\n",
    "quant_sel = [0.25, 0.75]\n",
    "\n",
    "# Sample from predicted distribution\n",
    "pred_samples = lgblss.predict(\n",
    "    test_features_no_outliers,\n",
    "    pred_type=\"samples\",\n",
    "    n_samples=n_samples,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Calculate quantiles from predicted distribution\n",
    "pred_quantiles = lgblss.predict(\n",
    "    test_features_no_outliers,\n",
    "    pred_type=\"quantiles\",\n",
    "    n_samples=n_samples,\n",
    "    quantiles=quant_sel\n",
    ")\n",
    "\n",
    "# Return predicted distributional parameters\n",
    "pred_params = lgblss.predict(\n",
    "    test_features_no_outliers,\n",
    "    pred_type=\"parameters\"\n",
    ")\n",
    "\n",
    "lgblss.plot(test_features_no_outliers,\n",
    "            parameter=\"scale\",\n",
    "            plot_type=\"Feature_Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_point, geom_vline, stat_density, facet_wrap, labs, theme_bw, scale_fill_brewer, theme, element_text, element_blank\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "n_examples = 9\n",
    "\n",
    "for i in range(n_examples):    \n",
    "    y_samples = pd.DataFrame(pred_samples.values[i,:].reshape(-1,1), columns=[\"PREDICT_DENSITY\"])\n",
    "    y_samples[\"PREDICT_POINT\"] = y_samples[\"PREDICT_DENSITY\"].mean()\n",
    "    y_samples[\"PREDICT_Q05\"] = y_samples[\"PREDICT_DENSITY\"].quantile(q=quant_sel[0])\n",
    "    y_samples[\"PREDICT_Q95\"] = y_samples[\"PREDICT_DENSITY\"].quantile(q=quant_sel[1])\n",
    "    y_samples[\"ACTUAL\"] = test_target_no_outliers.iloc[i]\n",
    "    y_samples[\"obs\"]= f\"Obervation {i+1}\"\n",
    "    y_pred.append(y_samples)\n",
    "    \n",
    "pred_df = pd.melt(pd.concat(y_pred, axis=0), id_vars=\"obs\")\n",
    "pred_df[\"obs\"] = pd.Categorical(pred_df[\"obs\"], categories=[f\"Obervation {i+1}\" for i in range(n_examples)])\n",
    "df_actual, df_pred_dens, df_pred_point, df_q05, df_q95 = [x for _, x in pred_df.groupby(\"variable\")]\n",
    "\n",
    "plot_pred = (\n",
    "    ggplot(pred_df,\n",
    "           aes(color=\"variable\")) + \n",
    "    stat_density(df_pred_dens,\n",
    "                 aes(x=\"value\"),\n",
    "                 size=1.1) + \n",
    "    geom_point(df_pred_point,\n",
    "               aes(x=\"value\",\n",
    "                   y=0),\n",
    "               size=1.4) + \n",
    "    geom_point(df_actual,\n",
    "               aes(x=\"value\",\n",
    "                   y=0),\n",
    "               size=1.4) + \n",
    "    geom_vline(df_q05, \n",
    "               aes(xintercept=\"value\",\n",
    "                   fill=\"variable\",\n",
    "                   color=\"variable\"),\n",
    "               linetype=\"dashed\",\n",
    "               size=1.1) + \n",
    "    geom_vline(df_q95, \n",
    "               aes(xintercept=\"value\",\n",
    "                   fill=\"variable\",\n",
    "                   color=\"variable\"),\n",
    "               linetype=\"dashed\",\n",
    "               size=1.1) + \n",
    "    facet_wrap(\"obs\",\n",
    "               scales=\"free\",\n",
    "               ncol=3) + \n",
    "    labs(title=\"Predicted vs. Actual \\n\",\n",
    "         x = \"\") + \n",
    "    theme_bw(base_size=15) +\n",
    "    scale_fill_brewer(type=\"qual\", palette=\"Dark2\") + \n",
    "    theme(legend_position=\"bottom\",\n",
    "          plot_title = element_text(hjust = 0.5),\n",
    "          legend_title = element_blank()\n",
    "         )\n",
    ")\n",
    "\n",
    "print(plot_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
