{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "conn = sqlite3.connect('../data/nfp2/nfp2.db')  # Adjust the path to your database file\n",
    "\n",
    "# Step 2 & 3: Query the database and load the data into a pandas DataFrame\n",
    "query = \"SELECT * FROM stellarators\"  # Adjust your query as needed\n",
    "data_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "data_df_clean = data_df[data_df['convergence'] == 1]\n",
    "data_df_clean = data_df_clean.dropna(subset=['quasisymmetry'])\n",
    "\n",
    "\n",
    "X = data_df_clean[['rbc_1_0', 'rbc_m1_1', 'rbc_0_1', 'rbc_1_1','zbs_1_0', 'zbs_m1_1', 'zbs_0_1', 'zbs_1_1']] \n",
    "Y = np.log(data_df_clean['quasisymmetry'])\n",
    "\n",
    "features_no_outliers, test_features_no_outliers, target_no_outliers, test_target_no_outliers = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Weibull import *\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.kdeplot(target_no_outliers, bw_adjust=0.5)\n",
    "plt.title('Density Function')\n",
    "plt.xlabel('Log(quasisymmetry)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# from scipy.stats import norm\n",
    "\n",
    "\n",
    "\n",
    "# # Assuming `Y_train_np` is your 1D numpy array data\n",
    "# target_no_outliers_np = target_no_outliers.to_numpy().reshape(-1, 1)  # Reshape to 2D if necessary\n",
    "\n",
    "# # Use AIC and BIC to determine the best number of components for GMM\n",
    "# n_components_range = range(1, 10)  # Example range, can be adjusted\n",
    "# lowest_bic = np.infty\n",
    "# lowest_aic = np.infty\n",
    "# best_gmm = None\n",
    "# bic = []\n",
    "# aic = []\n",
    "\n",
    "# for n_components in n_components_range:\n",
    "#     # Fit a Gaussian mixture with n components\n",
    "#     gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "#     gmm.fit(target_no_outliers_np)\n",
    "    \n",
    "#     # Calculate the BIC and AIC\n",
    "#     bic.append(gmm.bic(target_no_outliers_np))\n",
    "#     aic.append(gmm.aic(target_no_outliers_np))\n",
    "    \n",
    "#     # Determine if this model has the lowest BIC\n",
    "#     if bic[-1] < lowest_bic:\n",
    "#         lowest_bic = bic[-1]\n",
    "#         best_gmm_bic = gmm\n",
    "        \n",
    "#     # Determine if this model has the lowest AIC\n",
    "#     if aic[-1] < lowest_aic:\n",
    "#         lowest_aic = aic[-1]\n",
    "#         best_gmm_aic = gmm\n",
    "\n",
    "# # Plot the BIC scores\n",
    "# plt.figure(figsize=(4, 2))\n",
    "# plt.plot(n_components_range, bic, label='BIC')\n",
    "# plt.plot(n_components_range, aic, label='AIC')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Criterion Value')\n",
    "# plt.title('BIC and AIC for GMM')\n",
    "# plt.show()\n",
    "\n",
    "# # Use the best model for the final density plot\n",
    "# best_gmm = best_gmm_bic if lowest_bic < lowest_aic else best_gmm_aic\n",
    "# print(f\"Selected Model Components: {best_gmm.n_components}\")\n",
    "\n",
    "# # Generate some data points for plotting the density\n",
    "# x = np.linspace(target_no_outliers_np.min(), target_no_outliers_np.max(), 1000).reshape(-1, 1)\n",
    "# logprob = best_gmm.score_samples(x)\n",
    "# responsibilities = best_gmm.predict_proba(x)\n",
    "# pdf = np.exp(logprob)\n",
    "# pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "# # Plot the actual kernel density estimation of your data\n",
    "# sns.kdeplot(target_no_outliers_np.flatten(), bw_adjust=0.5, label='Actual')\n",
    "\n",
    "# # Plot each component density\n",
    "# for i in range(best_gmm.n_components):\n",
    "#     plt.plot(x, pdf_individual[:, i], label=f'Gaussian {i+1}')\n",
    "\n",
    "# # Plot the total density\n",
    "# plt.plot(x, pdf, label='Mixture Total')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('Actual data density vs. Gaussian Mixture Model density')\n",
    "# plt.xlabel('Data values')\n",
    "# plt.ylabel('Density')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbmlss.distributions import Gaussian, StudentT, Gamma, Cauchy, LogNormal, Weibull, Gumbel, Laplace, Beta, Poisson, SplineFlow, NegativeBinomial\n",
    "# from lightgbmlss.distributions.distribution_utils import DistributionClass\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Your data preparation steps\n",
    "# target_no_outliers_np = np.array(target_no_outliers)\n",
    "\n",
    "# lgblss_dist_class = DistributionClass()\n",
    "# candidate_distributions = [Gaussian, StudentT, Gamma, Cauchy, LogNormal, Weibull, Gumbel, Laplace, Beta, Poisson, SplineFlow, NegativeBinomial]\n",
    "\n",
    "# # Selecting the best distribution based on negative log-likelihood\n",
    "# dist_nll = lgblss_dist_class.dist_select(target=target_no_outliers_np, candidate_distributions=candidate_distributions, max_iter=50, plot=True, figure_size=(8, 4))\n",
    "# dist_nll\n",
    "\n",
    "# # Plot the actual data density\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# sns.kdeplot(target_no_outliers_np, bw_adjust=0.5, label='Actual Data Density')\n",
    "# plt.title('Density Function of Target Data')\n",
    "# plt.xlabel('Data')\n",
    "# plt.ylabel('Density')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from lightgbmlss.distributions.Mixture import *\n",
    "from lightgbmlss.distributions.mixture_distribution_utils import MixtureDistributionClass\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "figure_size = (10,5)\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "plotnine.options.figure_size = figure_size\n",
    "\n",
    "\n",
    "# # Initialize the MixtureDistributionClass\n",
    "mix_dist_class = MixtureDistributionClass()\n",
    "\n",
    "# # Define the candidate distributions\n",
    "candidate_distributions = [\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=2),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=3),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=4),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=5),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=6),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=7),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=8),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=9),\n",
    "    Mixture(Gaussian(response_fn=\"softplus\"), M=10),\n",
    "]\n",
    "\n",
    "# Convert target to numpy array if not already\n",
    "target_no_outliers_np = np.array(target_no_outliers)\n",
    "\n",
    "# Selecting the best distribution based on negative log-likelihood\n",
    "dist_nll = mix_dist_class.dist_select(target=target_no_outliers_np, candidate_distributions=candidate_distributions, max_iter=50, plot=True, figure_size=(8, 5))\n",
    "\n",
    "# Output the negative log-likelihoods\n",
    "print(dist_nll)\n",
    "\n",
    "# Plot the actual data density\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(target_no_outliers_np, bw_adjust=0.5, label='Actual Data Density')\n",
    "plt.title('Density Function of Target Data')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "este grafico apenas ve a distribuição da target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before hyperparameter optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Weibull import *\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import signal\n",
    "\n",
    "dtrain = lgb.Dataset(features_no_outliers, label=target_no_outliers.values, params={'max_bin': 3000})\n",
    "\n",
    "# Initialize the LightGBMLSS model with the Mixture of Gaussians distribution\n",
    "# Specifies a mixture of Gaussians. See ?Mixture for an overview.\n",
    "lgblss = LightGBMLSS(\n",
    "    Weibull(stabilization=\"None\", response_fn=\"exp\", loss_fn=\"nll\")\n",
    ")\n",
    "\n",
    "# Define the parameter dictionary\n",
    "param_dict = {\n",
    "    \"eta\":                      [\"float\", {\"low\": 1e-5,   \"high\": 1,     \"log\": True}],\n",
    "    \"max_depth\":                [\"int\",   {\"low\": 1,      \"high\": 10,    \"log\": False}],\n",
    "    \"min_gain_to_split\":        [\"float\", {\"low\": 1e-8,   \"high\": 40,    \"log\": True}],\n",
    "    \"min_sum_hessian_in_leaf\":  [\"float\", {\"low\": 1e-8,   \"high\": 500,   \"log\": True}],\n",
    "    \"subsample\":                [\"float\", {\"low\": 0.2,    \"high\": 1.0,   \"log\": False}],\n",
    "    \"feature_fraction\":         [\"float\", {\"low\": 0.2,    \"high\": 1.0,   \"log\": False}],\n",
    "    \"boosting\":                 [\"categorical\", [\"gbdt\", 'dart']],\n",
    "}\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "print('Debug: Before hyperparameter optimization')\n",
    "\n",
    "np.random.seed(123)\n",
    "opt_param = lgblss.hyper_opt(param_dict,\n",
    "                             dtrain,\n",
    "                             num_boost_round=100,        # Number of boosting iterations.\n",
    "                             nfold=5,                    # Number of cv-folds.\n",
    "                             early_stopping_rounds=20,   # Number of early-stopping rounds\n",
    "                             max_minutes=60,             # Time budget in minutes, i.e., stop study after the given number of minutes.\n",
    "                             n_trials=20,                # The number of trials. If this argument is set to None, there is no limitation on the number of trials.\n",
    "                             silence=True,               # Controls the verbosity of the trail, i.e., user can silence the outputs of the trail.\n",
    "                             seed=123,                   # Seed used to generate cv-folds.\n",
    "                             hp_seed=None                # Seed for random number generator used in the Bayesian hyperparameter search.\n",
    "                            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lightgbmlss.model import LightGBMLSS  # Ensure this import matches your actual usage\n",
    "\n",
    "# Seed for reproducibility in numpy operations\n",
    "np.random.seed(123)\n",
    "\n",
    "# Assuming opt_param is defined somewhere in your code\n",
    "opt_params = opt_param.copy()\n",
    "n_rounds = opt_params[\"opt_rounds\"]\n",
    "del opt_params[\"opt_rounds\"]\n",
    "\n",
    "# Assuming dtrain is defined and is an appropriate dataset for training\n",
    "# Train Model with optimized hyperparameters\n",
    "lgblss.train(opt_params, dtrain, num_boost_round=n_rounds)\n",
    "\n",
    "# Seed for reproducibility in torch operations\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Number of samples to draw from predicted distribution\n",
    "n_samples = len(test_target_no_outliers)  # Use the number of rows in X_test as the number of samples\n",
    "\n",
    "# Quantiles to calculate from predicted distribution\n",
    "quant_sel = [0.05, 0.95]\n",
    "\n",
    "# Sample from predicted distribution\n",
    "pred_samples = lgblss.predict(\n",
    "    X_test,\n",
    "    pred_type=\"samples\",\n",
    "    n_samples=n_samples,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Calculate quantiles from predicted distribution\n",
    "pred_quantiles = lgblss.predict(\n",
    "    X_test,\n",
    "    pred_type=\"quantiles\",\n",
    "    n_samples=n_samples,\n",
    "    quantiles=quant_sel\n",
    ")\n",
    "\n",
    "# Return predicted distributional parameters\n",
    "pred_params = lgblss.predict(\n",
    "    X_test,\n",
    "    pred_type=\"parameters\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({\n",
    "    \"Predicted\": pred_samples.flatten(),  # Flatten in case the predictions are in a 2D array\n",
    "    \"Type\": \"Predicted\"\n",
    "})\n",
    "df_actual = pd.DataFrame({\n",
    "    \"Predicted\": np.tile(Y_test, (len(pred_samples) // len(Y_test))),\n",
    "    \"Type\": \"Actual\"\n",
    "})\n",
    "\n",
    "# Combine and plot\n",
    "df_combined = pd.concat([df_predictions, df_actual])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df_combined, x=\"Predicted\", hue=\"Type\", fill=True)\n",
    "plt.title('Density Plot of Predicted Outputs vs Actual Values')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_quantiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance of scale parameter\n",
    "lgblss.plot(X_test,\n",
    "            parameter=\"scale\",\n",
    "            plot_type=\"Feature_Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_means = pred_params['concentration']\n",
    "predicted_variances = pred_params['scale']\n",
    "\n",
    "# Calculate standard deviation from variance\n",
    "predicted_std = np.sqrt(predicted_variances)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) as one option for mean error\n",
    "mean_error = np.mean(np.abs(predicted_means - Y_test))\n",
    "\n",
    "# For Mean Squared Error (MSE), use:\n",
    "# mean_squared_error = np.mean((predicted_means - Y_test) ** 2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Error (MAE): {mean_error}\")\n",
    "print(f\"Standard Deviation: {predicted_std.mean()}\")  # Average standard deviation across all predictions\n",
    "\n",
    "# Note: The calculation of standard deviation's average might need adjustments based on your specific requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_point, geom_vline, stat_density, facet_wrap, labs, theme_bw, scale_fill_brewer, theme, element_text, element_blank\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "n_examples = 9\n",
    "\n",
    "for i in range(n_examples):    \n",
    "    y_samples = pd.DataFrame(pred_samples.values[i,:].reshape(-1,1), columns=[\"PREDICT_DENSITY\"])\n",
    "    y_samples[\"PREDICT_POINT\"] = y_samples[\"PREDICT_DENSITY\"].mean()\n",
    "    y_samples[\"PREDICT_Q05\"] = y_samples[\"PREDICT_DENSITY\"].quantile(q=quant_sel[0])\n",
    "    y_samples[\"PREDICT_Q95\"] = y_samples[\"PREDICT_DENSITY\"].quantile(q=quant_sel[1])\n",
    "    y_samples[\"ACTUAL\"] = Y_test.iloc[i]\n",
    "    y_samples[\"obs\"]= f\"Obervation {i+1}\"\n",
    "    y_pred.append(y_samples)\n",
    "    \n",
    "pred_df = pd.melt(pd.concat(y_pred, axis=0), id_vars=\"obs\")\n",
    "pred_df[\"obs\"] = pd.Categorical(pred_df[\"obs\"], categories=[f\"Obervation {i+1}\" for i in range(n_examples)])\n",
    "df_actual, df_pred_dens, df_pred_point, df_q05, df_q95 = [x for _, x in pred_df.groupby(\"variable\")]\n",
    "\n",
    "plot_pred = (\n",
    "    ggplot(pred_df,\n",
    "           aes(color=\"variable\")) + \n",
    "    stat_density(df_pred_dens,\n",
    "                 aes(x=\"value\"),\n",
    "                 size=1.1) + \n",
    "    geom_point(df_pred_point,\n",
    "               aes(x=\"value\",\n",
    "                   y=0),\n",
    "               size=1.4) + \n",
    "    geom_point(df_actual,\n",
    "               aes(x=\"value\",\n",
    "                   y=0),\n",
    "               size=1.4) + \n",
    "    geom_vline(df_q05, \n",
    "               aes(xintercept=\"value\",\n",
    "                   fill=\"variable\",\n",
    "                   color=\"variable\"),\n",
    "               linetype=\"dashed\",\n",
    "               size=1.1) + \n",
    "    geom_vline(df_q95, \n",
    "               aes(xintercept=\"value\",\n",
    "                   fill=\"variable\",\n",
    "                   color=\"variable\"),\n",
    "               linetype=\"dashed\",\n",
    "               size=1.1) + \n",
    "    facet_wrap(\"obs\",\n",
    "               scales=\"free\",\n",
    "               ncol=3) + \n",
    "    labs(title=\"Predicted vs. Actual \\n\",\n",
    "         x = \"\") + \n",
    "    theme_bw(base_size=15) +\n",
    "    scale_fill_brewer(type=\"qual\", palette=\"Dark2\") + \n",
    "    theme(legend_position=\"bottom\",\n",
    "          plot_title = element_text(hjust = 0.5),\n",
    "          legend_title = element_blank()\n",
    "         )\n",
    ")\n",
    "\n",
    "print(plot_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP WITH FEATURES AND MEAN ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "# Calculate the absolute error for each prediction\n",
    "absolute_errors = np.abs(predicted_means - Y_test)\n",
    "\n",
    "# Combine the features and the errors into one DataFrame for t-SNE/UMAP\n",
    "tsne_features = X_test.copy()\n",
    "tsne_features['absolute_error'] = absolute_errors\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "tsne_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Option 1: Drop rows with NaNs (if they were inf/-inf)\n",
    "tsne_features.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Initialize UMAP. You can adjust n_neighbors and min_dist as needed.\n",
    "reducer = umap.UMAP(n_neighbors=200, min_dist=1, n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features (excluding the 'absolute_error' column)\n",
    "embedding = reducer.fit_transform(tsne_features.drop('absolute_error', axis=1))\n",
    "\n",
    "# Now, let's create the plot using UMAP results\n",
    "plt.figure(figsize=(10,6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                      c=tsne_features['absolute_error'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Mean Absolute Error')\n",
    "plt.title('UMAP plot with points colored by prediction error')\n",
    "plt.xlabel('UMAP Feature 1')\n",
    "plt.ylabel('UMAP Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP WITH FEATURES AND STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace inf/-inf with NaN in your features\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Check if there are any NaN values and handle them\n",
    "if X_test.isnull().values.any():\n",
    "    # Impute the NaNs or drop the rows/columns with NaN values.\n",
    "    # Here we impute with the mean, but you might want to consider other imputation methods\n",
    "    X_test = X_test.fillna(X_test.mean())\n",
    "\n",
    "# Ensure no infinite values in predicted_variances before calculating the standard deviation\n",
    "predicted_variances = np.where(np.isfinite(predicted_variances), predicted_variances, np.nan)\n",
    "predicted_variances = np.nan_to_num(predicted_variances, nan=np.nanmean(predicted_variances))\n",
    "predicted_std = np.sqrt(predicted_variances)\n",
    "\n",
    "# Normalize your features to ensure they don't contain too large values\n",
    "scaler = MinMaxScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Combine the scaled features and the standard deviations into one DataFrame for UMAP\n",
    "umap_features = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "umap_features['std_dev'] = predicted_std\n",
    "\n",
    "# Initialize UMAP. You can adjust n_neighbors and min_dist as needed.\n",
    "reducer = umap.UMAP(n_neighbors=200, min_dist=1, n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features (excluding the 'std_dev' column)\n",
    "embedding = reducer.fit_transform(umap_features.drop('std_dev', axis=1))\n",
    "\n",
    "# Now, let's create the plot using UMAP results\n",
    "plt.figure(figsize=(12,8))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                      c=umap_features['std_dev'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Standard Deviation')\n",
    "plt.title('UMAP plot with points colored by standard deviation')\n",
    "plt.xlabel('UMAP Feature 1')\n",
    "plt.ylabel('UMAP Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP WITH TARGET AND MEAN ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "# Calculate the absolute error for each prediction\n",
    "absolute_errors = np.abs(predicted_means - Y_test)\n",
    "f_t = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "# Combine the features and the errors into one DataFrame for t-SNE/UMAP\n",
    "tsne_features = f_t.copy()\n",
    "tsne_features['absolute_error'] = absolute_errors\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "tsne_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Option 1: Drop rows with NaNs (if they were inf/-inf)\n",
    "tsne_features.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Initialize UMAP. You can adjust n_neighbors and min_dist as needed.\n",
    "reducer = umap.UMAP(n_neighbors=200, min_dist=1, n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features (excluding the 'absolute_error' column)\n",
    "embedding = reducer.fit_transform(tsne_features.drop('absolute_error', axis=1))\n",
    "\n",
    "# Now, let's create the plot using UMAP results\n",
    "plt.figure(figsize=(10,6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                      c=tsne_features['absolute_error'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Mean Absolute Error')\n",
    "plt.title('UMAP plot with points colored by prediction error')\n",
    "plt.xlabel('UMAP Feature 1')\n",
    "plt.ylabel('UMAP Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP WITH TARGET AND STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `X_test` and `Y_test` are pandas DataFrames and `predicted_variances` is a numpy array\n",
    "\n",
    "# Replace inf/-inf with NaN and then drop or impute NaN values for both X_test and Y_test\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "Y_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Assuming you want to impute NaN values, do it for both\n",
    "X_test = X_test.fillna(X_test.mean())\n",
    "Y_test = Y_test.fillna(Y_test.mean())\n",
    "\n",
    "# Combine X_test and Y_test into a single DataFrame\n",
    "combined_data = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "# Normalize your features to ensure they don't contain too large values\n",
    "scaler = MinMaxScaler()\n",
    "combined_data_scaled = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Combine the scaled features into one DataFrame for UMAP\n",
    "umap_features = pd.DataFrame(combined_data_scaled, columns=combined_data.columns)\n",
    "\n",
    "# Initialize UMAP\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "embedding = reducer.fit_transform(umap_features)\n",
    "\n",
    "# Ensure no infinite values in predicted_variances before calculating the standard deviation\n",
    "predicted_variances = np.where(np.isfinite(predicted_variances), predicted_variances, np.nan)\n",
    "predicted_variances = np.nan_to_num(predicted_variances, nan=np.nanmean(predicted_variances))\n",
    "predicted_std = np.sqrt(predicted_variances)\n",
    "\n",
    "# Add standard deviation to the UMAP features for coloring the plot\n",
    "umap_features['std_dev'] = predicted_std\n",
    "\n",
    "# Now, let's create the plot using UMAP results\n",
    "plt.figure(figsize=(12,8))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                      c=umap_features['std_dev'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Standard Deviation')\n",
    "plt.title('UMAP plot with points colored by standard deviation')\n",
    "plt.xlabel('UMAP Feature 1')\n",
    "plt.ylabel('UMAP Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
